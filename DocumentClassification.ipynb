{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from sklearn.datasets import load_files \n",
    "from keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "rawData = load_files(r\"/Users/karthekeyanmani/Downloads/bbc\")  \n",
    "X, y = list(map(str,rawData.data)), to_categorical(np.asarray(list(map(int,rawData.target))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text data\n",
    "max_words = 1000\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequence = tokenizer.texts_to_sequences(X)\n",
    "X_tansformed = tokenizer.sequences_to_matrix(sequences=sequence,mode='count')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tansformed, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "Train on 1341 samples, validate on 149 samples\n",
      "Epoch 1/10\n",
      "1341/1341 [==============================] - 2s 1ms/sample - loss: 1.0255 - accuracy: 0.7032 - val_loss: 0.2515 - val_accuracy: 0.9463\n",
      "Epoch 2/10\n",
      "1341/1341 [==============================] - 0s 213us/sample - loss: 0.1960 - accuracy: 0.9381 - val_loss: 0.2200 - val_accuracy: 0.9597\n",
      "Epoch 3/10\n",
      "1341/1341 [==============================] - 0s 212us/sample - loss: 0.0927 - accuracy: 0.9761 - val_loss: 0.1838 - val_accuracy: 0.9597\n",
      "Epoch 4/10\n",
      "1341/1341 [==============================] - 0s 212us/sample - loss: 0.0491 - accuracy: 0.9873 - val_loss: 0.1786 - val_accuracy: 0.9530\n",
      "Epoch 5/10\n",
      "1341/1341 [==============================] - 0s 209us/sample - loss: 0.0311 - accuracy: 0.9955 - val_loss: 0.1685 - val_accuracy: 0.9597\n",
      "Epoch 6/10\n",
      "1341/1341 [==============================] - 0s 213us/sample - loss: 0.0286 - accuracy: 0.9940 - val_loss: 0.1639 - val_accuracy: 0.9597\n",
      "Epoch 7/10\n",
      "1341/1341 [==============================] - 0s 210us/sample - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.1576 - val_accuracy: 0.9530\n",
      "Epoch 8/10\n",
      "1341/1341 [==============================] - 0s 210us/sample - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.1677 - val_accuracy: 0.9530\n",
      "Epoch 9/10\n",
      "1341/1341 [==============================] - 0s 209us/sample - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.1621 - val_accuracy: 0.9664\n",
      "Epoch 10/10\n",
      "1341/1341 [==============================] - 0s 214us/sample - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.1870 - val_accuracy: 0.9530\n",
      "735/1 - 0s - loss: 0.1040 - accuracy: 0.9592\n",
      "Test loss: 0.16599219134267496\n",
      "Test accuracy: 0.9591837\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.save_weights\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(rawData.target_names)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.metrics_names)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1,callbacks=[tensorboard])\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrdictClass(text):\n",
    "    Seq = tokenizer.texts_to_sequences([text])\n",
    "    valX = tokenizer.sequences_to_matrix(sequences=Seq,mode='count')\n",
    "    pre = model.predict_classes(valX)\n",
    "    return rawData.target_names[pre[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'politics'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(\"test.txt\", \"r\")\n",
    "PrdictClass(text.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
